{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT 4 - Wrangle Twitter data via API (made in Vscode)"
   ]
  },
  {
   "source": [
    "## Table of Contents\n",
    "* [Introduction](#intro)\n",
    "* [Initial Brief](#1.1-initial-brief)\n",
    "* [General Outline](#general_outline)\n",
    "* [Import Libraries](#)\n",
    "* [](#)\n",
    "\n",
    "`Note: Fill at the end. Automate with python library/extension.`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Introduction\n",
    "Gather readily available data from an existing source on the web to allow first hand experience of wrangling data.<br>\n",
    "It is a significant task as data will not always be provided and if it is: <br>\n",
    " - Best case: Spelling mistakes and/or equivalent,\n",
    " - Worst case: No schema/format, duplicates, incomplete and/or incorrect values recorded."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Initial Brief\n",
    "- User has provided archived twitter data for analysis\n",
    " - [ ] Twitter archive export in CSV\n",
    " - [ ] URL to Machine Learning image predictions\n",
    "<br>\n",
    "- Identify minimum:\n",
    " - [ ] 8 quality issues\n",
    " - [ ] 2 tidiness issues\n",
    "<br>\n",
    "- Out of scope:\n",
    " - [ ] Unique rating system\n",
    " - [ ] No gathering required past 01 Aug 2017"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## General outline\n",
    "- [ ] Read-in CSV data\n",
    "- [ ] Access URL data (_over manually downloading file_)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## install modules via terminal\n",
    "#pip install pandas # also downloads numpy\n",
    "#pip install requests\n",
    "#pip install tweepy\n",
    "#pip install pandasgui\n",
    "#pip install autoviz\n",
    "#pip install pandas-profiling\n",
    "#pip install sweetviz\n",
    "#pip install bs4\n",
    "\n",
    "## Optional - provides Table of Contents and minimizes lines (only on Jupyter)\n",
    "#pip install jupyter_contrib_nbextensions && jupyter contrib nbextension install"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Import Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "import msvcrt\n",
    "import sys\n",
    "\n",
    "from pandasgui import show\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import tweepy\n",
    "\n",
    "import json\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "source": [
    "## Defined Functions\n",
    "\n",
    "- addFiles(filename)    `Created for the ability to scale`\n",
    "- go_assess(df)         `Created to reiterate through assessment steps`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = [] # declare\n",
    "print('{} Files in list'.format(len(filelist)) ) # initial print\n",
    "\n",
    "# Adds and tracks files\n",
    "def add_files(*filename): # PARAMETER: <string>\n",
    "    for file in filename:\n",
    "        filelist.append(file)\n",
    "        print('{} added to file list.'.format(file) )\n",
    "\n",
    "    if len(filelist) > 1:\n",
    "        print('{} files now in list.'.format( len(filelist)) )\n",
    "    else:\n",
    "        print('{} file now in list.'.format( len(filelist)) )\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(df, col, name): # \n",
    "    export = []\n",
    "    value_cnt = col.value_counts()\n",
    "    value = value_cnt.values\n",
    "# test for duplicates, no duplicates should be equal to .series size\n",
    "    if value.sum() > value.shape[0]: # there are duplicates\n",
    "        txt_result = ('Duplicates found in column \\'{}\\', the max duplicate item repeats {} times.'.format(name, value.max()) ) # print results, return indexes\n",
    "    else: # no duplicates\n",
    "        txt_result = ('No duplicates found in column \\'{}\\'.'.format(name) )\n",
    "        #print('{}: No duplicates found.'.format(col) )\n",
    "    # pack variables into list\n",
    "    export.append(value_cnt)\n",
    "    export.append(txt_result)\n",
    "    \n",
    "    return export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_assess(df):\n",
    "    # empty every function call, to prevent list from accumulating over time\n",
    "    results = [] #\n",
    "    summary = [] #\n",
    "    val_sum = [] # \n",
    "    assessment = []\n",
    "    print('Dataframe contains the following columns:')\n",
    "    print('{}\\n'.format(df.columns) )\n",
    "\n",
    "    for i, col in enumerate(df.columns):\n",
    "        # copy into message\n",
    "        print('Column {} - \\'{}\\' has been assessed. Assessment saved in results[{}] and summary[{}]'.format(i, col, i, i))\n",
    "        \n",
    "        # call and get results\n",
    "        val_sum = get_values(df, df[col], col)\n",
    "\n",
    "        # append results\n",
    "        summary.append(val_sum[1])\n",
    "        results.append(val_sum[0])\n",
    "\n",
    "    assessment.append(summary)\n",
    "    assessment.append(results)\n",
    "    print('NOTE: To access variables, set a series name e.g below:\\nseries[0][x] to access summary details.\\nseries[1][x] to access the value_counts results.\\nx represents column number')\n",
    "    return assessment #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_strings(df):\n",
    "    for col in df:\n",
    "        if df[col].dtype == 'object':\n",
    "            startcount = df[col].str.len()\n",
    "            df[col].str.strip()\n",
    "            endcount = df[col].str.len()\n",
    "            print\n",
    "\n",
    "            if (startcount.sum() - endcount.sum()) > 0:\n",
    "                print('Whitespaces were present in {}.'.format(col) )\n",
    "            else:\n",
    "                print('No whitespaces in {}.'.format(col) )"
   ]
  },
  {
   "source": [
    "## Data Wrangling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Iteration 1\n",
    "Import data from a twitter user archive provided by the end-user\n",
    "\n",
    "`Note: Add edit# upon addition of new issue.`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Gathering 1\n",
    "#### Initialize\n",
    "Enter Known Input Info\n",
    "Format: file name inside ''"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE 1 - TWITTER ARCHIVE DATA\n",
    "folder = 'Incoming_Files/'\n",
    "twitter_file = 'twitter-archive-enhanced-2.csv'\n",
    "add_files(twitter_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE 2 - TWITTER ML IMAGE PREDICTIONS\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "\n",
    "# assign to a response object\n",
    "response = requests.get(url)\n",
    "\n",
    "image_predictions = url.split('/')[-1] # extract file name\n",
    "\n",
    "# with open, allows for the auto close file when complete\n",
    "# split after last delimiter /, indicating file name\n",
    "with open(os.path.join(folder, image_predictions), mode='wb') as file:\n",
    "    # read file \n",
    "    file.write(response.content)\n",
    "    print('{} has been saved in: \"/{}\"'.format(image_predictions, folder) )\n",
    "\n",
    "# call function and add name to end of list\n",
    "add_files(image_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_script = str(input('Run script to Access Twitter API (Y/N)?'))\n",
    "valid_input = ['n', 'N', 'y', 'Y']\n",
    "yes_list = ['y','Y']\n",
    "no_list = ['n','N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FILE 3 - TWITTER API JSON\n",
    "# run python script, pass dataframe name (dataframe could not be passed)\n",
    "while run_script not in valid_input:\n",
    "    run_script = input('Wrong input. Run script to Access Twitter API (Y/N)?')\n",
    "\n",
    "if run_script in yes_list:\n",
    "    folderarg = folder.replace(' ', '_')\n",
    "    print('Running. Will indicate when complete.\\n')\n",
    "    %run twitter-api.py $folderarg $filelist[0]\n",
    "elif run_script in no_list:\n",
    "    print('Script not running.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Twitter API data\n",
    "API_cols = ['tweet_id', 'retweet_count', 'fav_count']\n",
    "\n",
    "# read in txt and convert to json\n",
    "API_export = 'tweet_json.txt'\n",
    "# call function and add name to end of list\n",
    "add_files(API_export)\n",
    "\n",
    "json_keys, json_id, json_fav_count, json_retweet_cnt = [], [],[],[]\n",
    "\n",
    "with open(API_export) as txt_file:\n",
    "    for line in txt_file:\n",
    "        #print(line)\n",
    "        json_obj = json.loads(line)\n",
    "        #append to list then combine lists \n",
    "        json_keys.append(json_obj)\n",
    "        json_id.append(json_obj['id_str'])\n",
    "        json_fav_count.append(json_obj['favorite_count'])\n",
    "        json_retweet_cnt.append(json_obj['retweet_count'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_obj"
   ]
  },
  {
   "source": [
    "#### Import into dataframes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # IMPROVE\n",
    " # create empty list\n",
    "df_raw = []\n",
    "file_extensions = []\n",
    "\n",
    "# dataframe to contain original imports\n",
    "for num, file in enumerate(filelist):\n",
    "    ext = file.split('.')[-1]\n",
    "    file_extensions.append(ext)\n",
    "    # read extension type\n",
    "    ## catch CSV, TSV, JSON, no Switch/Case in Python\n",
    "    if ext == 'csv':\n",
    "        df_raw.append(pd.read_csv(folder + file) )\n",
    "    elif ext == 'tsv':\n",
    "        df_raw.append(pd.read_csv(folder + file, sep='\\t') )\n",
    "    elif file == 'tweet_json.txt': # improve for general twitter api scrap import\n",
    "        df_raw.append(pd.DataFrame(zip(json_id, json_fav_count, json_retweet_cnt), columns=API_cols))\n",
    "    else:\n",
    "        print('filelist({}) - \"{}\", could not be read into a dataframe.'.format(num, filelist[num]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[0].sample(3)  # visually assess file was read in correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = df_raw[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[1].sample(3)  # visually assess file was read in correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictor = df_raw[1].copy() # create copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[2].sample(3)  # visually assess file was read in correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_api = df_raw[2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_api.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO - search Incoming Files directory, files not in list to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Assessing data\n",
    "### Assess 1 - Twitter Data Archive\n",
    "#### Define:<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external windows open\n",
    "twitter_gui = show(df_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call go_assess function\n",
    "archive_assessed = go_assess(df_twitter)"
   ]
  },
  {
   "source": [
    "### Column 0 - tweet_id"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 0 - \n",
    "archive_assessed[0][0], archive_assessed[1][0]"
   ]
  },
  {
   "source": [
    "### Column 1 - in reply"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 1 - \n",
    "archive_assessed[0][1], archive_assessed[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter[df_twitter.in_reply_to_status_id.notna()]['in_reply_to_status_id'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 2 - \n",
    "archive_assessed[0][2], archive_assessed[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 3 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_assessed[0][3], archive_assessed[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 4 - \n",
    "archive_assessed[0][4], archive_assessed[1][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 5 - \n",
    "archive_assessed[0][5], archive_assessed[1][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 6 - \n",
    "archive_assessed[0][6], archive_assessed[1][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 7 - \n",
    "archive_assessed[0][7], archive_assessed[1][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 8 - \n",
    "archive_assessed[0][8], archive_assessed[1][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 9 - \n",
    "archive_assessed[0][9], archive_assessed[1][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 10 - \n",
    "archive_assessed[0][10], archive_assessed[1][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 11 - \n",
    "archive_assessed[0][11], archive_assessed[1][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 12 - name"
   ]
  },
  {
   "source": [
    "archive_assessed[0][12], archive_assessed[1][12]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Assess 2 - Twitter Image Predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external windows open\n",
    "predictions_gui = show(df_raw[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictor.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictor.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_assessed = go_assess(df_image_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 0\n",
    "img_assessed[0][0], img_assessed[1][0]"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 1\n",
    "# search for files other then .jpg, use .split and sift through values\n",
    "not_jpg = df_image_predictor[~df_image_predictor.jpg_url.str.contains('.jpg',)]\n",
    "not_jpg.jpg_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_assessed[0][1], img_assessed[1][1]"
   ]
  },
  {
   "source": [
    "### Column 2\n",
    "img_assessed[0][2], img_assessed[1][2]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 3\n",
    "img_assessed[0][3], img_assessed[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_ws = df_image_predictor[df_image_predictor.p1.str.contains(' ',)]\n",
    "is_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = img_assessed[1][3] == 1\n",
    "img_assessed[1][3][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 4\n",
    "img_assessed[0][4], img_assessed[1][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 5\n",
    "img_assessed[0][5], img_assessed[1][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictor.query('p1_dog == False').iloc[:, [0,1,3,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_false_results = df_image_predictor.query('p1_dog == False').iloc[:,:6]\n",
    "p1_false_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_false_results.groupby(['p1']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 6\n",
    "img_assessed[0][6], img_assessed[1][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 7\n",
    "img_assessed[0][7], img_assessed[1][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 8\n",
    "img_assessed[0][8], img_assessed[1][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 9\n",
    "img_assessed[0][9], img_assessed[1][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 10\n",
    "img_assessed[0][10], img_assessed[1][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 11\n",
    "img_assessed[0][11], img_assessed[1][11]"
   ]
  },
  {
   "source": [
    "## Assess 3 - Twitter API Raw Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external windows open\n",
    "api_gui = show(df_raw[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_api.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_api.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_api.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assess raw json api data\n",
    "api_assessed = go_assess(df_twitter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_assessed = go_assess(df_twitter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_assessed[0][0], api_assessed[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_assessed[0][1], api_assessed[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_assessed[0][2], api_assessed[1][2]"
   ]
  },
  {
   "source": [
    "### Assess Iteration 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = []\n",
    "df_clean.append(df_twitter)\n",
    "df_clean.append(df_image_predictor)\n",
    "df_clean.append(df_twitter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_clean:\n",
    "    print(df.shape)"
   ]
  },
  {
   "source": [
    "## Cleaning data\n",
    "### Quality Issue 1:\n",
    "#### Define:\n",
    "col0: tweet_id data type change to string, all dataframes\n",
    "\n",
    "#### Code:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = 'tweet_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print previous data types \n",
    "df_image_predictor[q1].head(1)\n",
    "for df in df_clean:\n",
    "    print(df[q1].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to string\n",
    "for df in df_clean:\n",
    "    df[q1] = df[q1].astype(str)"
   ]
  },
  {
   "source": [
    "#### Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictor[q1].head(1)\n",
    "for i, df in enumerate(df_clean):\n",
    "    print(df[q1].head(1))"
   ]
  },
  {
   "source": [
    "### Quality issue 2:\n",
    "#### Define:\n",
    "col3: change timestamp datatype to datetime"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Code:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].timestamp = pd.to_datetime(df_clean[0].timestamp)"
   ]
  },
  {
   "source": [
    "#### Test:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].timestamp"
   ]
  },
  {
   "source": [
    "### Quality Issue 3:\n",
    "#### Define:\n",
    "col4: split string to remove html tag and extract content within"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_assessed[1][4]"
   ]
  },
  {
   "source": [
    "#### Code:\n",
    "strip string prior to splitting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].iloc[:,4] = df_clean[0].iloc[:,4].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESET COLUMN if coded incorrectly\n",
    "df_clean[0].iloc[:,4] = df_raw[0].iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].iloc[:,4] = df_clean[0].iloc[:,4].apply(lambda text: BeautifulSoup(text, 'html.parser').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].rename(columns={'source':'source_app'}, inplace=True)"
   ]
  },
  {
   "source": [
    "#### Test:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].iloc[:,4].value_counts()"
   ]
  },
  {
   "source": [
    "### Quality Issue 4:\n",
    "#### Define:\n",
    "col1,2,6,7: change datatype from float to int\n",
    "#### Code:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4 = list(df_twitter.iloc[:0, [1,2,6,7]])\n",
    "# Print previous data types \n",
    "for column in q4:\n",
    "    print(df_twitter[column].head(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to string\n",
    "for column in q4:\n",
    "    df_twitter[column] = df_twitter[column].astype(str)"
   ]
  },
  {
   "source": [
    "#### Test:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in q4:\n",
    "    print(df_twitter[column].head(0))"
   ]
  },
  {
   "source": [
    "### Quality Issue 5:\n",
    "#### Define:\n",
    "remove potential whitespaces across all string/objects, trim front and end as visual inspection appeared to show start of strings not inline when scrolling down."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].info()"
   ]
  },
  {
   "source": [
    "#### Code & Test:\n",
    "`Improvement opportunity. Scan for object/string dtype and return if true to easily filter`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function\n",
    "trim_strings(df_clean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_strings(df_clean[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_strings(df_clean[2])"
   ]
  },
  {
   "source": [
    "### Quality Issue 6:\n",
    "#### Define:\n",
    "df_image_predictor<br>\n",
    "col3,6,9: change to lower case"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6 = list(df_clean[1].iloc[:0, [3,6,9]])"
   ]
  },
  {
   "source": [
    "#### Code:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6 = list(df_clean[1].iloc[:0, [3,6,9]])\n",
    "# Print previous data types \n",
    "for column in q6:\n",
    "    print(df_clean[1][column].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESET COLUMN if coded incorrectly\n",
    "df_clean[1].iloc[:, [3,6,9]] = df_raw[1].iloc[:, [3,6,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in q6:\n",
    "    df_clean[1][column] = df_clean[1][column].str.lower()"
   ]
  },
  {
   "source": [
    "#### Test:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in q6:\n",
    "    print(df_clean[1][column].head(5))"
   ]
  },
  {
   "source": [
    "### Quality Issue 7:\n",
    "#### Define:\n",
    "col1: rename from jpg_url to img_url"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[1].iloc[:0, 1]"
   ]
  },
  {
   "source": [
    "#### Code:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[1].rename(columns={'jpg_url':'img_url'}, inplace=True)"
   ]
  },
  {
   "source": [
    "#### Test:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[1].iloc[:0, 1]"
   ]
  },
  {
   "source": [
    "### Quality Issue 8:\n",
    "#### Define:\n",
    "col2: rename from img_num to conf_tweet_img"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Code:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[1].iloc[:0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Quality Issue 8:\n",
    "df_clean[1].rename(columns={'img_num':'conf_tweet_img'}, inplace=True)"
   ]
  },
  {
   "source": [
    "#### Test:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[1].iloc[:0, 2]"
   ]
  },
  {
   "source": [
    "### Quality Issue 9:\n",
    "#### Define:\n",
    "<br>check col12 to remove/replace incorrect names with None"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Code:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = df_clean[0].name.value_counts().index\n",
    "names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract names - regex test\n",
    "name_mask = df_clean[0].name.str.match('[^A-Z]')\n",
    "name_mask.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].name[name_mask].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].name.where(~name_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].name = df_clean[0].name.where(~name_mask,None)"
   ]
  },
  {
   "source": [
    "#### Test:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].name"
   ]
  },
  {
   "source": [
    "### Quality Issue 10:\n",
    "#### Define:\n",
    "<br>check numerator rating value is correct."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview of strings in text column\n",
    "list(df_clean[0].text.sample(5) )"
   ]
  },
  {
   "source": [
    "#### Code:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex filter to extract 123.34/123 found visually and programmatically\n",
    "df_clean[0]['rating'] = df_clean[0].text.str.extract(r'(\\b\\d{0,3}\\.?\\d{1,2}\\/\\d{2,3})', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0]['rating'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove .13 and .10 manually\n",
    "# remove .13\n",
    "x = df_clean[0].query('rating==\".13/10\"').rating.index[0]\n",
    "df_clean[0]['rating'].iloc[x] = df_clean[0]['rating'].iloc[x].split('.')[1]\n",
    "df_clean[0]['rating'].iloc[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove .10\n",
    "x = df_clean[0].query('rating==\".10/10\"').rating.index[0]\n",
    "df_clean[0]['rating'].iloc[x] = df_clean[0]['rating'].iloc[x].split('.')[1]\n",
    "df_clean[0]['rating'].iloc[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].rating.value_counts(dropna=False), df_clean[0].rating.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for non regex matches\n",
    "checknull = df_clean[0].rating.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_clean[0][checknull].text), list(df_clean[0][checknull].rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimal_mask = df_clean[0].rating.str.contains('\\.', na=False) # to remove error\n",
    "decimal_mask.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0][decimal_mask].rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimal_index = df_clean[0][decimal_mask].index\n",
    "decimal_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ratings = df_clean[0].rating.str.split('/', n=2, expand=True).astype(float)\n",
    "mid = clean_ratings[0].median()\n",
    "clean_ratings[0].fillna(mid, inplace=True)\n",
    "clean_ratings[1].fillna(10, inplace=True)\n",
    "clean_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ratings[0].dtype, clean_ratings[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ratings[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ratings[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].rating_numerator = clean_ratings[0].astype(float)\n",
    "df_clean[0].rating_denominator = clean_ratings[1].astype(int)"
   ]
  },
  {
   "source": [
    "#### Test:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].rating_denominator.isnull().values.any(), df_clean[0].rating_numerator.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].drop('rating', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].rating_numerator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].info()"
   ]
  },
  {
   "source": [
    "### Quality Issue 11:\n",
    "#### Define:\n",
    "remove retweets, i.e. 'RT @' in text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].in_reply_to_user_id.value_counts()"
   ]
  },
  {
   "source": [
    "#### Code:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0] = df_clean[0].query('in_reply_to_user_id==\"nan\" & retweeted_status_user_id==\"nan\"')"
   ]
  },
  {
   "source": [
    "#### Test:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].in_reply_to_user_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].retweeted_status_id.value_counts()"
   ]
  },
  {
   "source": [
    "### Tidiness Issue 1:\n",
    "#### Define:\n",
    "timestamp split into three columns, date, time, timezone"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].shape, df_clean[1].shape, df_clean[2].shape"
   ]
  },
  {
   "source": [
    "#### Code:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter.timestamp.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0]['date'] = df_clean[0]['timestamp'].dt.date \n",
    "df_clean[0]['time'] = df_clean[0]['timestamp'].dt.time \n",
    "df_clean[0]['timezone'] = df_clean[0]['timestamp'].astype(str).str[-6:]\n",
    "df_clean[0].drop(labels='timestamp', axis=1, inplace = True)"
   ]
  },
  {
   "source": [
    "#### Test:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].iloc[:,16:]"
   ]
  },
  {
   "source": [
    "### Tidiness Issue 2:\n",
    "#### Define:\n",
    "categorize dog type into one column, and drop redundant columns.\n",
    "### Quality Issue #:\n",
    "#### Define:\n",
    "change datatype into categorical"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].iloc[:,11:16].sample(10)"
   ]
  },
  {
   "source": [
    "#### Code:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0]['dog_type'] = df_clean[0].text.str.extract('(doggo|floofer|pupper|puppo)', expand=False)\n",
    "df_clean[0]['dog_type'] = df_clean[0]['dog_type'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = list(df_clean[0].iloc[:1,12:16])\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0]['dog_type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0]['dog_type'].fillna('doggo', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0]['dog_type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "#### Test:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0]['dog_type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_clean[0].iloc[:0,:])"
   ]
  },
  {
   "source": [
    "### Tidiness Issue 3:\n",
    "#### Define:\n",
    "merge dataframes to contain the relevant columns required for analysis ensuring each is relevant to the information it pertains. Two dataframes in total.\n",
    "One observation consisting of Twitter Data, another consisting of image predictions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Code:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge twitter archive and api data first, keep predictions at the end (width wise) of data frame\n",
    "twitter_archive_master = pd.merge(df_clean[0], df_clean[2], on='tweet_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master = pd.merge(twitter_archive_master, df_clean[1], on='tweet_id', how='inner')"
   ]
  },
  {
   "source": [
    "#### Test:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.info()"
   ]
  },
  {
   "source": [
    "### Tidiness Issue 4:\n",
    "#### Define:\n",
    "drop redundant columns, retweeted and in_reply columns, four (4) in total"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Code:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = list(twitter_archive_master.iloc[:0,[1,2,5,6,7,8]])\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "source": [
    "#### Test:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[1].head()"
   ]
  },
  {
   "source": [
    "## Save Clean data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'Working_Files'\n",
    "#from pathlib import Path\n",
    "Path(directory).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Twitter Master file\n",
    "filename_out1 = 'twitter_archive_master.csv'\n",
    "twitter_archive_master.to_csv(directory+'/'+filename_out1, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def move_file(folder, file):\n",
    "    path = os.getcwd()\n",
    "    dest = path+'/'+folder+'/'+file\n",
    "    source = path+'/'+file\n",
    "\n",
    "    shutil.move(source, dest)\n",
    "    print('{} moved.'.format(file))"
   ]
  },
  {
   "source": [
    "## Exploratory Data Analysis and Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.info()"
   ]
  },
  {
   "source": [
    "### Automated EDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Sweetviz"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz as sv\n",
    "\n",
    "sweetviz_file1 = 'SweetViz-Twitter_Data_Report.html'\n",
    "sweetviz_file2 = 'SweetViz-Img_Predictions_Report.html'\n",
    "\n",
    "# Clean\n",
    "clean_report1 = sv.analyze([twitter_archive_master,'Twitter_Data'])\n",
    "clean_report1.show_html(filepath=sweetviz_file1, open_browser=False)\n",
    "print('')\n",
    "# Raw\n",
    "raw_report1 = sv.analyze([df_raw[0],'Twitter_Data_Raw'])\n",
    "raw_report1.show_html(filepath='Raw_'+sweetviz_file1, open_browser=False)\n",
    "print('')\n",
    "raw_report2 = sv.analyze([df_raw[0], 'Image_Predictions_Raw'])\n",
    "raw_report2.show_html(filepath='Raw_'+sweetviz_file2, open_browser=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_report2 = sv.analyze([df_image_predictor, 'Image_Predictions'])\n",
    "clean_report2.show_html(filepath=sweetviz_file2, open_browser=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move into Reports Folder\n",
    "#dest = path+'/'+folder+'/'+file\n",
    "#source = path+'/'+file\n",
    "move_file('Reports', sweetviz_file1)\n",
    "move_file('Reports', sweetviz_file2)\n",
    "move_file('Reports', 'Raw_'+sweetviz_file1)\n",
    "move_file('Reports', 'Raw_'+sweetviz_file2)"
   ]
  },
  {
   "source": [
    "#### Pandas Profiling\n",
    "Limitation of n=10000 data points to be analysed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from pandas_profiling import ProfileReport"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "##### Twitter data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "twitter_profile = ProfileReport(twitter_archive_master, title=\"Pandas_Profiling-Twitter_Data_Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_profile(profile, rep_name):\n",
    "    prof_directory = 'Reports'\n",
    "    Path(prof_directory).mkdir(parents=True, exist_ok=True)\n",
    "    profile.to_file(prof_directory + '/' + rep_name + '.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_profile.to_widgets() # to display report above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save report as html, provide profile and report name\n",
    "pandasprof = 'Twitter_Report.html'\n",
    "twitter_profile.to_file(pandasprof)\n",
    "move_file('Reports', pandasprof)"
   ]
  },
  {
   "source": [
    "### Manual Visualization\n",
    "#### Tableau Public"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<div class='tableauPlaceholder' id='viz1607928848578' style='position: relative'><noscript><a href='#'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;We&#47;WeLoveDogsTwitterData&#47;Dashboard1&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='WeLoveDogsTwitterData&#47;Dashboard1' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;We&#47;WeLoveDogsTwitterData&#47;Dashboard1&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1607928848578');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='650px';vizElement.style.height='887px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='650px';vizElement.style.height='887px';} else { vizElement.style.width='100%';vizElement.style.height='1577px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<div class='tableauPlaceholder' id='viz1607928908675' style='position: relative'><noscript><a href='#'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;We&#47;WeLoveDogsTwitterData&#47;Dashboard2&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='WeLoveDogsTwitterData&#47;Dashboard2' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;We&#47;WeLoveDogsTwitterData&#47;Dashboard2&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1607928908675');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='650px';vizElement.style.height='887px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='650px';vizElement.style.height='887px';} else { vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*1.77)+'px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<div class='tableauPlaceholder' id='viz1607928926606' style='position: relative'><noscript><a href='#'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;We&#47;WeLoveDogsTwitterData&#47;Dashboard3&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='WeLoveDogsTwitterData&#47;Dashboard3' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;We&#47;WeLoveDogsTwitterData&#47;Dashboard3&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1607928926606');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='650px';vizElement.style.height='887px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='650px';vizElement.style.height='887px';} else { vizElement.style.width='100%';vizElement.style.height='527px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "562ec6405976493db7174998c6f199dd03aea2fb718069d5cdee13b378ce47b2"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}