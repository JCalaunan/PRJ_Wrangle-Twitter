{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT 4 - Wrangle Twitter data via API"
   ]
  },
  {
   "source": [
    "## Table of Contents\n",
    "* [Introduction](#intro)\n",
    "* [Initial Brief](#1.1-initial-brief)\n",
    "* [General Outline](#general_outline)\n",
    "* [Import Libraries](#)\n",
    "* [](#)\n",
    "* [](#)\n",
    "\n",
    "`Note: Fill at the end. Automate with python library/extension.`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Introduction\n",
    "Gather readily available data from an existing source on the web to allow first hand experience of wrangling data.<br>\n",
    "It is a significant task as data will not always be provided and if it is: <br>\n",
    " - Best case: Spelling mistakes and/or equivalent,\n",
    " - Worst case: No schema/format, duplicates, incomplete and/or incorrect values recorded."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Initial Brief\n",
    "- User has provided archived twitter data for analysis\n",
    " - [ ] Twitter archive export in CSV\n",
    " - [ ] URL to Machine Learning image predictions\n",
    "<br>\n",
    "- Identify minimum:\n",
    " - [ ] 8 quality issues\n",
    " - [ ] 2 tidiness issues\n",
    "<br>\n",
    "- Out of scope:\n",
    " - [ ] Unique rating system\n",
    " - [ ] No gathering required past 01 Aug 2017"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## General outline\n",
    "- [ ] Read-in CSV data\n",
    "- [ ] Access URL data (_over manually downloading file_)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## install modules via terminal\n",
    "#pip install pandas # also downloads numpy\n",
    "#pip install requests\n",
    "#pip install tweepy\n",
    "\n",
    "## Optional - provides TOC\n",
    "#pip install jupyter_contrib_nbextensions"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "source": [
    "## Import Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "import tweepy"
   ]
  },
  {
   "source": [
    "## Defined Functions\n",
    "\n",
    "- addFiles(filename)    `Created for the ability to scale`\n",
    "- go_assess(df)         `Created to reiterate through assessment steps`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 Files in list\n"
     ]
    }
   ],
   "source": [
    "filelist = [] # declare\n",
    "print('{} Files in list'.format(len(filelist)) ) # initial print\n",
    "\n",
    "# Adds and tracks files\n",
    "def add_files(*filename): # PARAMETER: <string>\n",
    "    for file in filename:\n",
    "        filelist.append(file)\n",
    "        print('{} added to file list.'.format(file) )\n",
    "\n",
    "    if len(filelist) > 1:\n",
    "        print('{} files now in list.'.format( len(filelist)) )\n",
    "    else:\n",
    "        print('{} file now in list.'.format( len(filelist)) )\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(df, col, name): # \n",
    "    export = []\n",
    "    value_cnt = col.value_counts()\n",
    "    value = value_cnt.values\n",
    "# test for duplicates, no duplicates should be equal to .series size\n",
    "    if value.sum() > value.shape[0]: # there are duplicates\n",
    "        txt_result = ('Duplicates found in column \\'{}\\', the max duplicate item repeats {} times.'.format(name, value.max()) ) # print results, return indexes\n",
    "    else: # no duplicates\n",
    "        txt_result = ('No duplicates found in column \\'{}\\'.'.format(name) )\n",
    "        #print('{}: No duplicates found.'.format(col) )\n",
    "    # pack variables into list\n",
    "    export.append(value_cnt)\n",
    "    export.append(txt_result)\n",
    "    \n",
    "    return export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assessment = [] # create global\n",
    "def go_assess(df):\n",
    "    # empty every function call, to prevent list from accumulating over time\n",
    "    results = [] #\n",
    "    summary = [] #\n",
    "    val_sum = [] # \n",
    "    assessment = []\n",
    "    print('Dataframe contains the following columns:')\n",
    "    print('{}\\n'.format(df.columns) )\n",
    "\n",
    "    for i, col in enumerate(df.columns):\n",
    "        # copy into message\n",
    "        print('Column {} - \\'{}\\' has been assessed. Assessment saved in results[{}] and summary[{}]'.format(i, col, i, i))\n",
    "        \n",
    "        # call and get results\n",
    "        val_sum = get_values(df, df[col], col)\n",
    "\n",
    "        # append results\n",
    "        summary.append(val_sum[1])\n",
    "        results.append(val_sum[0])\n",
    "\n",
    "    assessment.append(summary)\n",
    "    assessment.append(results)\n",
    "    print('NOTE: To access variables, set a series name e.g below:\\nseries[0][x] to access summary details.\\nseries[1][x] to access the value_counts results.\\nx represents column number')\n",
    "    return assessment #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BLANK"
   ]
  },
  {
   "source": [
    "## Data Wrangling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Iteration 1\n",
    "Import data from a twitter user archive provided by the end-user\n",
    "\n",
    "`Note: Add edit# upon addition of new issue.`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Gathering 1\n",
    "#### Initialize\n",
    "Enter Known Input Info\n",
    "Format: file name inside ''"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "twitter-archive-enhanced-2.csv added to file list.\n1 file now in list.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'twitter-archive-enhanced-2.csv'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# FILE 1 - TWITTER ARCHIVE DATA\n",
    "folder = 'Incoming Files/'\n",
    "twitter_file = 'twitter-archive-enhanced-2.csv'\n",
    "add_files(twitter_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "image-predictions.tsv has been saved in: \"/Incoming Files/\"\nimage-predictions.tsv added to file list.\n2 files now in list.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'image-predictions.tsv'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# FILE 2 - TWITTER ML IMAGE PREDICTIONS\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "\n",
    "# assign to a response object\n",
    "response = requests.get(url)\n",
    "\n",
    "image_predictions = url.split('/')[-1] # extract file name\n",
    "\n",
    "# with open, allows for the auto close file when complete\n",
    "# split after last delimiter /, indicating file name\n",
    "with open(os.path.join(folder, image_predictions), mode='wb') as file:\n",
    "    # read file \n",
    "    file.write(response.content)\n",
    "    print('{} has been saved in: \"/{}\"'.format(image_predictions, folder) )\n",
    "\n",
    "# call function and add name to end of list\n",
    "add_files(image_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "#### Import into dataframes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " # create empty list\n",
    "df_raw = []\n",
    "file_extensions = []\n",
    "\n",
    "# dataframe to contain original imports\n",
    "for num, file in enumerate(filelist):\n",
    "    ext = file.split('.')[-1]\n",
    "    file_extensions.append(ext)\n",
    "    # read extension type\n",
    "    ## catch CSV, TSV, JSON, no Switch/Case in Python\n",
    "    if ext == 'csv':\n",
    "        df_raw.append(pd.read_csv(folder + file) )\n",
    "    elif ext == 'tsv':\n",
    "        df_raw.append(pd.read_csv(folder + file, sep='\\t') )\n",
    "    else:\n",
    "        print('filelist({}) - \"{}\", could not be read into a dataframe.'.format(num, filelist[num]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['twitter-archive-enhanced-2.csv', 'image-predictions.tsv']\n"
     ]
    }
   ],
   "source": [
    "print(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "83    876537666061221889                    NaN                  NaN   \n",
       "149   863079547188785154           6.671522e+17         4.196984e+09   \n",
       "2209  668623201287675904                    NaN                  NaN   \n",
       "\n",
       "                      timestamp  \\\n",
       "83    2017-06-18 20:30:39 +0000   \n",
       "149   2017-05-12 17:12:53 +0000   \n",
       "2209  2015-11-23 02:52:48 +0000   \n",
       "\n",
       "                                                 source  \\\n",
       "83    <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "149   <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2209  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                   text  retweeted_status_id  \\\n",
       "83    I can say with the pupmost confidence that the...                  NaN   \n",
       "149   Ladies and gentlemen... I found Pipsy. He may ...                  NaN   \n",
       "2209  This is Jomathan. He is not thrilled about the...                  NaN   \n",
       "\n",
       "      retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "83                         NaN                        NaN   \n",
       "149                        NaN                        NaN   \n",
       "2209                       NaN                        NaN   \n",
       "\n",
       "                                          expanded_urls  rating_numerator  \\\n",
       "83    https://twitter.com/mpstowerham/status/8761629...                14   \n",
       "149   https://twitter.com/dog_rates/status/863079547...                14   \n",
       "2209  https://twitter.com/dog_rates/status/668623201...                10   \n",
       "\n",
       "      rating_denominator      name doggo floofer pupper puppo  \n",
       "83                    10      None  None    None   None  None  \n",
       "149                   10      None  None    None   None  None  \n",
       "2209                  10  Jomathan  None    None   None  None  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>in_reply_to_status_id</th>\n      <th>in_reply_to_user_id</th>\n      <th>timestamp</th>\n      <th>source</th>\n      <th>text</th>\n      <th>retweeted_status_id</th>\n      <th>retweeted_status_user_id</th>\n      <th>retweeted_status_timestamp</th>\n      <th>expanded_urls</th>\n      <th>rating_numerator</th>\n      <th>rating_denominator</th>\n      <th>name</th>\n      <th>doggo</th>\n      <th>floofer</th>\n      <th>pupper</th>\n      <th>puppo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>83</th>\n      <td>876537666061221889</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017-06-18 20:30:39 +0000</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>I can say with the pupmost confidence that the...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://twitter.com/mpstowerham/status/8761629...</td>\n      <td>14</td>\n      <td>10</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>863079547188785154</td>\n      <td>6.671522e+17</td>\n      <td>4.196984e+09</td>\n      <td>2017-05-12 17:12:53 +0000</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>Ladies and gentlemen... I found Pipsy. He may ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://twitter.com/dog_rates/status/863079547...</td>\n      <td>14</td>\n      <td>10</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2209</th>\n      <td>668623201287675904</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2015-11-23 02:52:48 +0000</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>This is Jomathan. He is not thrilled about the...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://twitter.com/dog_rates/status/668623201...</td>\n      <td>10</td>\n      <td>10</td>\n      <td>Jomathan</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df_raw[0].sample(3)  # visually assess file was read in correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = df_raw[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                tweet_id                                          jpg_url  \\\n",
       "1848  839549326359670784  https://pbs.twimg.com/media/C6atpTLWYAIL7bU.jpg   \n",
       "232   670417414769758208  https://pbs.twimg.com/media/CU3NE8EWUAEVdPD.jpg   \n",
       "902   700029284593901568  https://pbs.twimg.com/media/CbcA673XIAAsytQ.jpg   \n",
       "\n",
       "      img_num                           p1   p1_conf  p1_dog               p2  \\\n",
       "1848        1                        swing  0.393527   False  Norwich_terrier   \n",
       "232         1                   sea_urchin  0.493257   False        porcupine   \n",
       "902         1  West_Highland_white_terrier  0.726571    True      Maltese_dog   \n",
       "\n",
       "       p2_conf  p2_dog              p3   p3_conf  p3_dog  \n",
       "1848  0.052480    True        Pembroke  0.049901    True  \n",
       "232   0.460565   False         cardoon  0.008146   False  \n",
       "902   0.176828    True  Dandie_Dinmont  0.070134    True  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>jpg_url</th>\n      <th>img_num</th>\n      <th>p1</th>\n      <th>p1_conf</th>\n      <th>p1_dog</th>\n      <th>p2</th>\n      <th>p2_conf</th>\n      <th>p2_dog</th>\n      <th>p3</th>\n      <th>p3_conf</th>\n      <th>p3_dog</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1848</th>\n      <td>839549326359670784</td>\n      <td>https://pbs.twimg.com/media/C6atpTLWYAIL7bU.jpg</td>\n      <td>1</td>\n      <td>swing</td>\n      <td>0.393527</td>\n      <td>False</td>\n      <td>Norwich_terrier</td>\n      <td>0.052480</td>\n      <td>True</td>\n      <td>Pembroke</td>\n      <td>0.049901</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>232</th>\n      <td>670417414769758208</td>\n      <td>https://pbs.twimg.com/media/CU3NE8EWUAEVdPD.jpg</td>\n      <td>1</td>\n      <td>sea_urchin</td>\n      <td>0.493257</td>\n      <td>False</td>\n      <td>porcupine</td>\n      <td>0.460565</td>\n      <td>False</td>\n      <td>cardoon</td>\n      <td>0.008146</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>902</th>\n      <td>700029284593901568</td>\n      <td>https://pbs.twimg.com/media/CbcA673XIAAsytQ.jpg</td>\n      <td>1</td>\n      <td>West_Highland_white_terrier</td>\n      <td>0.726571</td>\n      <td>True</td>\n      <td>Maltese_dog</td>\n      <td>0.176828</td>\n      <td>True</td>\n      <td>Dandie_Dinmont</td>\n      <td>0.070134</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df_raw[1].sample(3)  # visually assess file was read in correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictor = df_raw[1].copy() # create copy"
   ]
  },
  {
   "source": [
    "### Gathering 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1: 892420643555336193\n",
      "Success\n",
      "2: 892177421306343426\n",
      "Success\n",
      "3: 891815181378084864\n",
      "Success\n",
      "4: 891689557279858688\n",
      "Success\n",
      "5: 891327558926688256\n",
      "Success\n",
      "6: 891087950875897856\n",
      "Success\n",
      "7: 890971913173991426\n",
      "Success\n",
      "8: 890729181411237888\n",
      "Success\n",
      "9: 890609185150312448\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d5b2925de239>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\": \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mtweet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'extended'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Success\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_json\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# Execute request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                     resp = self.session.request(self.method,\n\u001b[0m\u001b[0;32m    185\u001b[0m                                                 \u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                                                 \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    528\u001b[0m         }\n\u001b[0;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    424\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    419\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1347\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1348\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "auth = OAuthHandler(consumer_key.strip(), consumer_secret.strip())\n",
    "auth.set_access_token(access_token.strip(), access_secret.strip())\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "tweet_ids = df_twitter.tweet_id.values\n",
    "len(tweet_ids)\n",
    "\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended') \n",
    "            print(\"Success\")\n",
    "            json.dump(tweet._json, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"Fail\")\n",
    "            fails_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timer()\n",
    "print(end - start)\n",
    "print(fails_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE 3 - TWITTER API JSON\n",
    "#%run twitter-api.py df_twitter # run python script, pass dataframe"
   ]
  },
  {
   "source": [
    "## Assessing data\n",
    "### Assess 1 - Twitter Data Archive\n",
    "#### Define:<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "**Visual and programmatic summary**<br>\n",
    "Exceptions:\n",
    "1. ratings (numerator, denominator)\n",
    "\n",
    "_Tidiness_<br>\n",
    "1. Datatypes\n",
    "1.1 Time stamp contains date and time, the timestamp can be split further\n",
    "1.2 Columns 13-16 can be categorized into `Dog_Category`, values repeat the column name making it irrelevant\n",
    "\n",
    "_Cleanliness_<br>\n",
    "1 Missing information, Columns ordered by severity:<br>\n",
    "1.1 Index 1-2 only has 78 non null values, a significant amount<br>\n",
    "1.2 Index 6-8 contain 181 non null values<br>\n",
    "1.3 Index 9 contains 2297 non null values<br>\n",
    "2 Datatypes:<br>\n",
    "2.1 float required for column 1-2 as the order is +17 providing no need for the precision of decimals\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call go_assess\n",
    "archive_assessed = go_assess(df_twitter)"
   ]
  },
  {
   "source": [
    "### Column 0 - tweet_id"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 0 - \n",
    "archive_assessed[0][0], archive_assessed[1][0]"
   ]
  },
  {
   "source": [
    "### Column 1 - in reply"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 1 - \n",
    "archive_assessed[0][1], archive_assessed[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter[df_twitter.in_reply_to_status_id.notna()]['in_reply_to_status_id'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 2 - \n",
    "archive_assessed[0][2], archive_assessed[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 3 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_assessed[0][3], archive_assessed[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 4 - \n",
    "archive_assessed[0][4], archive_assessed[1][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 5 - \n",
    "archive_assessed[0][5], archive_assessed[1][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 6 - \n",
    "archive_assessed[0][6], archive_assessed[1][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 7 - \n",
    "archive_assessed[0][7], archive_assessed[1][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 12 - name"
   ]
  },
  {
   "source": [
    "archive_assessed[0][12], archive_assessed[1][12]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Assess 2 - Twitter Image Predictions\n",
    "### Define:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictor.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictor.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_assessed = go_assess(df_image_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 0\n",
    "img_assessed[0][0], img_assessed[1][0]"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 1\n",
    "# search for files other then .jpg, use .split and sift through values\n",
    "not_jpg = df_image_predictor[~df_image_predictor.jpg_url.str.contains('.jpg',)]\n",
    "not_jpg.jpg_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_assessed[0][1], img_assessed[1][1]"
   ]
  },
  {
   "source": [
    "### Column 2\n",
    "img_assessed[0][2], img_assessed[1][2]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 3\n",
    "img_assessed[0][3], img_assessed[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_ws = df_image_predictor[df_image_predictor.p1.str.contains(' ',)]\n",
    "is_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = img_assessed[1][3] == 1\n",
    "img_assessed[1][3][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 4\n",
    "img_assessed[0][4], img_assessed[1][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 5\n",
    "img_assessed[0][5], img_assessed[1][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictor.query('p1_dog == False').iloc[:, [0,1,3,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_df = df_image_predictor.query('p1_dog == False').iloc[:,:6]\n",
    "p1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_df.groupby(['p1']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 6\n",
    "img_assessed[0][6], img_assessed[1][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 7\n",
    "img_assessed[0][7], img_assessed[1][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 8\n",
    "img_assessed[0][8], img_assessed[1][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 9\n",
    "img_assessed[0][9], img_assessed[1][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 10\n",
    "img_assessed[0][10], img_assessed[1][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column 11\n",
    "img_assessed[0][11], img_assessed[1][11]"
   ]
  },
  {
   "source": [
    "## Cleaning data\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change\n",
    "df_twitter.iloc[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc: Workspace"
   ]
  },
  {
   "source": [
    "## Save clean data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}